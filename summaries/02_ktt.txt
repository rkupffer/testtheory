#
# 04 KTT
#

Wdh: Testtheorie

    latent variable logic (01-grundlagen) 
    latent variable inference (01-grundlagen)

The battle of TT: classic vs. neo 

	* Klassische Testtheorie (KTT)
    * Item Response Theory (IRT) aka. modern test theory

Auf der KTT basieren die meisten der auf dem Markt erhältlichen psychologischen
Tests. Item Response Theorie (IRT) erlaubt Ergänzung und Weiterentwicklung der
KTT.

-- "The burden of complex social science measurement" -- 

Bei der Messung komplexer sozialwissenschaftlicher Konstrukte (z.B.
Intelligenz) treten Messfehler auf.

T = X + E

Bsp.: Verwechseln Probanden im Persönlichkeitstest zufällig das Antwortkästchen
variieren bei wiederholter Messung des Konstrukts (Testung) die Messwerte.

-- KTT als "Messfehlertheorie" --

KTT versucht den Messfehler zu quantifizieren

Ann.: E($\Epsilon) = 0

* d.h., die Fehler sind unsystematisch
* Idee: "Adding small fluctuations dampen one another"
* Why?  T = X + E | E(E) = 0 -> T = X
* Impl.: Mehritemmessung!

D.h.: Störeinflüsse, sind interessierenden Merkmal unkorreliert (cor(T,E)= 0) 

-- Problem(?) systematischer Störeinflüsse --

Problem: Da KTT nur unsystamtische Störeinflüsse berücksichtigt, bleiben
systematische Einflüsse unberücksichtigt.

z.B. (system.): Soziale Erwünschtheit, polt. Korreketheit

? Frage nach der Auswirkung systematischer Einflüsse

-- Auswirkungen von Messfehlern -- 

* Verringert die Konstruktvalidität
* (v.a.) Unterschätzung der Korrelation zweier Variablen
* Systematische Messfehler können 'confounds' krieren

SIMULATION

-- CTT: the true score ($\Tau) approach --

$\Tau$ : Messfehler bereinigte Merkmalsausprägung (given: $E(\Epsilon) = 0$)
$\Tau$ = E(X) | E(\Epsilon) = 0

Die True Score Logic in a Nutshell

Gedankenexperiment: Hätten wir die Möglichkeit eine Person i unzählige Male zu
unter den gleichen Bedinungen zu messen (m=1,...,M), dann erhalten wir eine
(Normal-)verteilung seiner Messwerte (unter der Annahme $E(\Epsilon) = 0$);
adding small fluctuations) wobei im Mittel über alle /intraindividuellen/
Messwerte (X_j=1,..., M) die Beobachtungswerte dem wahren Wert der Person
entsprechen (E(X_M) = T).
Erwartungswert := theoretischer Mittelwert

Da wir nur ein einzes Mal messen, ziehen wir (zufällig) einen Wert aus der
(Normal-)verteilung der intraindividuellen Messwerte. Dieser intraindividuelle
Messwert (X_j) ist ein Schätzer für den True Score (T) der Person der wegen des
Messfehlers unter oder über dem Messwert liegt (X_j >=< T).

-- Lokale Unabhängigkeit --
..eine Annahme der KTT und IRT

Lokale Unabhängigkeit <=> die Itemantworten sind unter Kontrolle der
Traitausprägung unabhängig voneinander 

Latent variable logic: Beinflusst die LV die OVs, kovariieren die Items
miteinander (LV_gen.process -> VAR(OVs) : cor(i, j) > 0). Ist die LV der
einzige Grund warum die Items korrelieren, dann sollte der Zusammenhang unter
Kontrolle der LV verschwinden. Die Items sind dann LSU und die LV erklärt/saugt
die gesamte Varianz zwischen den Items. Die Varianzaufklärungsmission ist damit
beendet (cov(i,j) = 0 | LV). D.h. OV := Indikator für LV <=> OVs lokal
statistisch unabhängig.

Hängt jedoch die Antworten zweier Items zusammen, dann korrelieren sie
ebenfalls miteinander -- auch unabhängig von der LV. Unter Kontrolle der LV
bleibt damit ein Rest übrig (d.h. nicht die gesamte Varianz wird durch die LV
herauspatrialisiert/-gesaugt). Die vollständige Varianzaufklärungsmission (im
Sinne der LV) ist damit gescheitert.

Lokale Abhängigkeit (Verletzung lokaler Unabhängigkeit)

verletzt <==> 
(1) logischen Abhängigkeiten zwischen Items 
z.B. man braucht vorherige Augabe um spätere Aufgäbe zu lösen
(2) systematischen Messfehlereinflüssen 
z.B. Antwortstilen und Konsistenzeffekten (?)

Konklusion: Bei einem Test, der ein eindimensionales Konstrukt erfasst, müssen
die Zusammenhänge zwischen Items bei lokaler Unabhängigkeit allein durch das
zugrundeliegende Konstrukt erklärbar sein (..wenn wir nicht die Möglichkeit die
Restvarianz anderweitig aufzuklären; in der KTT haben wir das in der Regel
nicht).

Note := LV in der IRT = Personenparameter

-- Grundgleichung der KTT -- 

y_ij= τ_ij+ ε_ij

Über alle Personen i (i = 1,…,n) hinweg:

Y_j= τ_j+ ε_j

-- Folgerungen aus der Grundgleichung der KTT -- 

Ziehen wir einen Person zufällig aus einer Population von Personen, dann...

1) E(Epsilon_j | \Tau_k) = 0 ; dann: E( X ) = T
	Der bedingte Erwartungswert* einer Messfehlervariablen ist für jede Ausprägung
	der True-Score-Variablen gleich 0. D.h. über die individuellen Messwerte vieler
	Individuen mit dem gleichen True-Score ($\Tau_k = j) hinweg, mittelen sich
	die individuellen Messfehler aus (Adding small flucations dampen one
	another..). 
	* lies: der theoretische Mittelwert im Hinblick auf...
1a) E(ε Narzissmus| τ Narzissmus = 10) = 0 ; Messung des selben Merkmals 
1b) E(ε Narzissmus| τ Intelligenz = 115) = 0 ; Messung unterschiedlicher Merkmals 

2) E(ε_j) = E(ε_j | τ_k) = E(ε_j | τ_l) = 0
	Anmkerkung: da sowohl (1a) als auch (1b) gilt; gilt allgemeiner -- der
	unbedingte Erwartungswert* einer Messfehlervariablen
	stets gleich 0. D.h. über die individuellen Messwerte vieler Individuen
	hinweg, mittelen sich die individuellen Messfehler aus (Adding small
	flucations dampen one another..). 
	* lies: der theoretische Mittelwert im Hinblick auf...

3) Cov(ε_j | τ_j) = Cov(ε_j | τ_k) = 0 ; dann  E(X) = T (bzw. Cov(x, τ) = 1)
	Messfehler- und (beliebige) True-Score-Variablen (k,l) sind unkorreliert.
	verletzt <=> Personen mit hohem (niedrigen) Wahrenwert profitieren (leiden)
	zusätzlich von Messfehlern [low scorer punishment ; high scorer benefit] 
	z.B.: im Intelligenztest profitieren intelligente Personen zusätzlich von Übungseffekten

(3+) Zusatzannahme: Cov(ε_j,ε_k)
	Die Messfehler bei der Messung zwei verschiedener Merkmale sind unabhängig;
	Überprüft man diese Annahme nicht, läuft man Gefahr, mit einem Test
	unwissentlich mehr als eine latente Dimension zu messen. (?)
	Tipp: Bevorzuge den Test mit der kleineren Fehlervarianz
	Note: weitere Hinweise bei Messmodellen

4) Var(Y_j) = Var(τ_j ) + Var(ε_j ) + 2*Cov(ε_j | τ_j) | Cov(ε_j | τ_j) = 0 =>
Var(τ_j) + Var(ε_j); 
	Die Varianz einer beobachteten Messwertvariablen lässt sich additiv
	zerlegen in die Varianz der True-Score-Variablen und die Varianz der
	Messfehlervariablen.
	z.B. Varianz bei der Messung von Narzissmus im Fragebogen geht zurück auf
	(a) tatsächliche Unterschiede der Probanden im Narzissmus (T) und (b)
	individuelle Abweichungen aufgrund der Messvarianz (burden of complex
	meassurment)

-- Reliabiliät --
..additive Varianzzerlegung => Grundlage: Definition der Reliabilität

Rel(Y_j) = Var(τ_j) / (Var(Y_j)) = Var(τ_j) / (Var(τ_j) + Var(ε_j))

	Die Reliabilität wird definiert als Anteil (Var(τ_j)) der wahren Varianz an
	der Gesamtvarianz (Var(Y_j)). Die Reliabilität ist also ein Maß für die
	Messfehlerfreiheit einer Messung 

Rel € [0,1] ; wobei: 0 -- nur Messfehler & 1 -- kein Messfehler, d.h.: X bildet
T perfekt ab.

Problem: Reliabilität <=>
	(1) Var(T): bekannt ; aber: unbekannt
	(2) Var(E): bekannt ; aber: unbekannt
2 Unbekannte: Gleichung ist unterminiert.

Behilfsmöglichkeiten? => Sitzung Reliabilität
Vorgeschmack Idee: Merkmal mindestens 2x messen
(1) Paralleltest
(2) Testhalbierung
(3) Testwiederholung-Methode
 
-- Messmodelle --

inwieweit messen wir mit unterschiedlichen Tests dasselbe messen
(Vergleichbarkeit, Messäquivalenz)

unterschiedliche Messmodelle bedingen unterschiedliche
Reliabilitätskoeffizienten.

Annamen der Messmodelle := f(Unkorreliertheit der Messfehler, 
							 Grad der Übereinstimmung der True Scores,
							 Fehlervarianzen)

Strenge (Rigidität) der Messmodelle:
Parallel > Essenziell parallel > Tau-äquivalent > Essenziell tau-äquivalent > Tau-kongenerisch

-- Modell paralleler Messung --

parallele Testform := Zwei Tests sollen exkat dasselbe messen (z.B. Intelligenztest) 

Annahmen: 
	1. Cov(ε_j | ε_k) = 0 (Unkorreliertheit der Messfehler)
	2. τ_j = τ_k (Identische wahre Werte)
	3. σ²_( ε_j ) = σ²_( ε_k ) (Identische Fehlervarianzen)

Wahre Werte und Fehlervarianzen sollen identisch sein!
Beobachtete Variablen müssen in (a) ihren Varianzen (b) Kovarianzen sowie (c)
Mittelwerten identisch sein.
z.B.: Messung: Körpergröße 2x hintereinander

Covmat: ident. Mittelwerte, ident. Var, ident. Cov, 

-- Modell essenziell paralleler Messungen --
essentiell := im Wesentlichen; d.h. es im wesentlichen parallel bis auf dass sie
sich um eine additive Konstante (alpha) unterscheiden dürfen.

Annahmen:
	1. Cov(ε_j | ε_k) = 0 (Unkorreliertheit der Messfehler) 
	2. τ_j= τ_k+ α (Wahre Werte unterscheiden sich um eine additive Konstante)
	3. σ²_( ε_j )= σ²_( ε_k ) (Identische Fehlervarianzen)
Note: alpha für alle Personen gleich;
z.B. Messung: Körpergröße 2x hintereinander Maßband; wobei Maßband + 5 

Covmat: Mittelwerte + alpha, ident. Var, ident. Cov, 

-- Modell tau-äquivalenter Messungen -- 

Annahmen:
	1. Cov(ε_j | ε_k) = 0 (Unkorrelierte Messfehler) 
	2. τ_j= τ_k (Identische wahre Werte)
	3. σ²_( ε_j ) ≠ σ²_( ε_k ) (unterschiedl. Fehlervarianzen)
Note: Die Reliabilität beider Messungen unterscheidet sich
z.B.: Gewichtsmessung; Waage 1 in Test 1: 3 Dezimalstellen -- Waage 2 in Test
2: 0 Dezimalstellen 

Covmat: ident. Mittelwerte, untersch. Var, ident. Cov, 

-- Modell essenziell tau-äquivalenter Messungen --

Annahmen:
	1. Cov(ε_j | ε_k) = 0 (Unkorrelierte Messfehler) 
	2. τ_j= τ_k+ α (Wahre Werte unterscheiden sich um eine additive Konstante)
	3. σ²_( ε_j ) ≠ σ²_( ε_k ) (unterschiedl. Fehlervarianzen)
Note: alpha für alle Personen gleich;

Bsp.: Messung des Gewichtes einer Schokoladentafel bei der ersten Messung ohne
Verpackung (alpha) auf einer Waage mit 3 Dezimalstellen und der zweiten Messung mit
Verpackung auf einer Waage mit 0 Dezimalstellen (sigma^2)

Covmat: ident. Mittelwerte, untersch. Var, ident. Cov, 

-- Modell tau-kongenerischer Messungen --
Annahmen: 
	1. Cov(ε_j | ε_k) = 0 (Unkorrelierte Messfehler) 
	2. τ_j= λ*τ_k + α (Wahre Werte stehen in einer linearen Beziehung zueinander)
		additive und multiplikative Konstante
	3. σ²_( ε_j ) ≠ σ²_( ε_k ) (unterschiedl. Fehlervarianzen)
Note: alpha und lambda für alle Personen gleich
Bsp: Messung der Körpergröße in cm und inch (selbe Eigenschaft, andere Metrik)

Covmat: untersch. Mittelwerte, untersch. Var, ident. Cov, 

Covmat: lambda * Mittelwerte + alpha, untersch. Var, untersch. Cov, 

-- Messmodelle -- 

(1) hierarchisch geordnet: restrikv -> allgemein ; Auflösung von Restriktionen
(2) empirische Gültigkeit der Modelle kann getestet werden
(3) Modelle geschachtelt => können direkt gegeneinander getestet werden.

-- Anwendung von Messmodellen --
(1) Reliabilitätsbestimmung
(2) Forschungsfragen 

Wann muss Messäquivalenz sichergestellt werden?

(1) Gruppenvergleiche; ist Messung gleich für unterschiedliche Gruppen?
	* Sind Frauen ängstlicher als Männer?
(2) Veränderungen über die Zeit ; ist Messung gleich zu unterschiedl. Zeitpunkten?
	* Veränderungen in der Gewissenhaftigkeit über die Lebensspanne?

Warum? Nur dann ist es möglich die Mittelwerte (Gruppen, bzw. im Zeitverlauf)
sicherzustellen.

Verletzung der Messäquivalenz
	Kann auftreten, wenn sich die psychometrischen Eigenschaften von Items
	verändern, z.B. ihre Schwierigkeit (Spinnen unter Drogen: "unmittelbar",
	"sofort")

Wichtig: Wie äußern sich verschiedene Messmodellen in einer Covmat! SIML?

Grenzen und Schwächen der KTT
	* Grundgleichung (T = X + E): nicht empirisch überprüfbar
	* Annahme zu Messfehlern (E(Epsilon) = 0): unsystematische Einflüsse
	Erweiterung für system. Einflüsse (z.B. Situations-, BEurteilungseffekte):
	Generalisierbarkeitstheorie 
	* Keine Möglichkeit die Homogenität der Items bezüglich des Merkmals
	  (Eindimensionalität) zu testen
	* Die Kennwerte der KTT (z. B. Reliabilitäten) sind stichprobenabhängig
