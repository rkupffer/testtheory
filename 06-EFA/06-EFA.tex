% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\title{Explorative Faktorenanalyse}
\author{Jalynskij et al.}
\date{}

\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usetheme[]{Boadilla}
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Explorative Faktorenanalyse},
  pdfauthor={Jalynskij et al.},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\begin{document}
\frame{\titlepage}

\begin{frame}{Einstieg}
\protect\hypertarget{einstieg}{}
\url{https://openpsychometrics.org/tests/IPIP-BFFM/1.php}
\end{frame}

\begin{frame}{Die ``Large Data Set Challenge''}
\protect\hypertarget{die-large-data-set-challenge}{}
\begin{example}
Stellen Sie sich vor, die von Ihnen soeben beantworteten Fragen ergäben die
Korrelationsmatrix $R$ auf der nächsten Folie. Die "Large Data Set Challenge"
lautet: Erkennen Sie eine Struktur in den Daten? D.h., wenn ja weiter; welche
Items könnten man Ihrer Meinung nach zu Itemgruppen zusammenfassen?
\end{example}

~

Anmerkung: Nein, das sind (wirklich) nicht ihre Antworten;
\(\texttt{V1 - V30}\) sind Zufallsvariablen!
\end{frame}

\begin{frame}[fragile]{Struktur erkennen \& Itemgruppen finden:
Übungsaufgabe 1}
\protect\hypertarget{struktur-erkennen-itemgruppen-finden-uxfcbungsaufgabe-1}{}
\begin{verbatim}
## Warning in sqrt(1 - diag(model)): NaNs produced
\end{verbatim}

\begin{center}\includegraphics[width=0.7\linewidth]{06-EFA_files/figure-beamer/unnamed-chunk-1-1} \end{center}
\end{frame}

\begin{frame}{Die ``Large Data Set Challenge''}
\protect\hypertarget{die-large-data-set-challenge-1}{}
\begin{alertblock}{Large Data Set Challenge}
Mit zunehmender Itemzahl nimmt die wird die Anzahl der Korrelationen, die für
eine Analyse zu berücksichtigen sind schnell zu. Die "Challenge" ist eine
mögliche Struktur zu erkennen!
\end{alertblock}

In a Nutshell:

\begin{itemize}
\tightlist
\item
  Problem: Anzahl der Korrelationen
\item
  z.B.: \(25\) Items \(\widehat{=}\) \(2^{25} = 625\) Korrelationen
\item
  Krux: Struktur erkennen
\item
  \(\Leftrightarrow\) finde: hoch korrelierende Itemgruppen
\end{itemize}
\end{frame}

\begin{frame}{Explorative Faktorenanalyse: in a Nutshell}
\protect\hypertarget{explorative-faktorenanalyse-in-a-nutshell}{}
\begin{itemize}
\tightlist
\item
  (ein) Hilfsmittel: .. (explorative) \textbf{Faktorenanalyse}
\end{itemize}

~

\begin{block}{Faktorenanalyse}
"The basic idea is to find latent variables (factors) based on the correlation
structure of the manifest input variables (indicators)." (Mair 2018, S. 23)
\end{block}

\begin{itemize}
\item
  andere Helferlein zur \emph{Datenreduktion} (eine Auswahl):

  \begin{itemize}
  \tightlist
  \item
    Hauptkomponentenanalyse
  \item
    Clusteranalyse
  \item
    Explorative Likertskalierung
  \item
    (Non-) Metric Data Scaling (Voraus.: Distanzmatrizen)
  \end{itemize}
\end{itemize}

Wichtig: ``meaningful compression'' vs.~``full compression''
\end{frame}

\begin{frame}{Stategie \& Vorgehen: Simulieren \& Evaluieren}
\protect\hypertarget{stategie-vorgehen-simulieren-evaluieren}{}
\begin{enumerate}
\tightlist
\item
  Man erschaffe \(\geq 1\) eine latente Variable (LV)
\item
  \ldots lasse die LV Antwortmuster produzieren
\item
  \ldots wandel sie in eine Korrelationsmatrix um
\item
  \ldots und versucht die Struktur mit der Faktorenanalyse aufzufinden
\end{enumerate}

~

\begin{block}{Vom generativen Prozess zur Korrelationsmatrix}
Der generative Prozess, d.h. wie genau ein Konstrukt die Antworten auf den Items
erzeugt, bleibt meist verborgen. Wir untersuchen meistens lediglich
Verhaltensspuren des Konstruktes, die sich in den Items ausdrückt, d.h. in der
Struktur der Korrelationsmatrix niederschlägt. Strukturen zu simulieren ist
hilfreich, weil wir dort "die Wahrheit" kennen und das Verfahren damit besser
beurteilen können ($\sim$ fake data analysis)
\end{block}
\end{frame}

\begin{frame}[fragile]{``Playing Creator'': Zwei latente Variable
erschaffen}
\protect\hypertarget{playing-creator-zwei-latente-variable-erschaffen}{}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Anzahl der Items}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{8}
\CommentTok{\# Faktorladungen}
\NormalTok{load\_F1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.6}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.7}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.3}\NormalTok{)}
\NormalTok{load\_F2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.7}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.7}\NormalTok{)}
\NormalTok{fx }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(load\_F1, load\_F2)}
\CommentTok{\# Zwischenfaktorkorrelation }
\NormalTok{phi }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)) ; phi[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ phi[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FloatTok{0.6}
\CommentTok{\# Struktur }
\NormalTok{S }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{sim.structure}\NormalTok{(fx, phi, }\AttributeTok{n=}\DecValTok{1000}\NormalTok{)}
\CommentTok{\# Korrelations{-} und Datenmatrix}
\NormalTok{R }\OtherTok{\textless{}{-}}\NormalTok{ S}\SpecialCharTok{$}\NormalTok{model ; X }\OtherTok{\textless{}{-}}\NormalTok{ S}\SpecialCharTok{$}\NormalTok{observed  }\CommentTok{\# R \textless{}{-} cor(X)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Vom generativen Prozess zur Korrelationsmatrix}
\protect\hypertarget{vom-generativen-prozess-zur-korrelationsmatrix}{}
\end{frame}

\begin{frame}{Prognose \& Selbstexperiment: Übungsaufgabe 2}
\protect\hypertarget{prognose-selbstexperiment-uxfcbungsaufgabe-2}{}
\begin{example}
Versuchen Sie es selbst! Verändern sie systematisch $\texttt{F1; F2}$  und
$\texttt{phi}$.
1. Wie verändert sich die Korrelationsmatrix, in Abhängigkeiten
Ihrer Veränderungen? 
2. Können Sie eine eindeutige Struktur konstruieren? 
3. Wenn ja, mit welchen Werten von $\texttt{F1; F2}$  und $\texttt{phi}$ haben Sie ihr Ziel
erreicht?
\end{example}

\begin{example}
Haben Sie ein Strukturmodell gefunden, dass ihnen gefällt? Ja, dann überlegen
Sie sich jetzt für welche Konstrukte diese Struktur Sinn macht (z.B.:
extraversion $\sim$ openness to experience)
\end{example}
\end{frame}

\begin{frame}{Logik latenter Variablen (..reversed)}
\protect\hypertarget{logik-latenter-variablen-..reversed}{}
\begin{block}{Von der Korrelationsmatrix zur LV} Die Faktoranalyse
ist ein strukturentdeckendes Verfahren. D.h. den generativen Prozess, d.h. wie
ein Konstrukt die Antworten auf den Items verursacht hat anhand der Struktur die
sich in der vorgegebenen Korrelationsmatrix zu \textit{modellieren}.
\end{block}

\begin{itemize}
\tightlist
\item
  Modell: \emph{Common Factor Model} (CFM)
\end{itemize}

\begin{alertblock}{Eingangsgleichung}
  \begin{equation}
    x = \Lambda \xi + \epsilon
  \end{equation}
\end{alertblock}

~

\begin{quote}
``In other words EFA tries to find \(p\) latent variables on the basis
of the correlation structure of the \(m\) manifest variables.'' (ebd.)
\end{quote}
\end{frame}

\begin{frame}{Das Common Factor Model (CFM)}
\protect\hypertarget{das-common-factor-model-cfm}{}
Anmerkung: Für die Reformulierung von Gleichung (1) zu (2): siehe
\href{http://dx.doi.org/10.4135/9780857020994.n6}{McCallum (2009)}

\begin{alertblock}{Fudnamentaltheorem}
  \begin{equation}
    P = \Lambda \Phi \Lambda^{t} + \Psi
  \end{equation}
\end{alertblock}

\begin{itemize}
\tightlist
\item
  \(P\): Modell-implizierte Korrelationsmatrix
\item
  \(\Lambda\): Ladungsmatrix
\item
  \(\Phi\): Matrix der Zwischenfaktorkorrelationen
\item
  \(\Psi\): Uniqueness
\end{itemize}

\begin{block}{Zusammenhang: Modell \& Struktur}
Die von ihnen konstruierte Struktur versuchen wir nun mit der Faktorenanalyse
unter Einsatz des CFM zu rekonstruieren. Das CFM ist also Ihr Tool im
bevorstehenden Rekonstruktionsprozess!
\end{block}
\end{frame}

\begin{frame}{Fakotrenanalyse: ``A hurdle race''}
\protect\hypertarget{fakotrenanalyse-a-hurdle-race}{}
\begin{enumerate}
\tightlist
\item
  Hürde: Extraktionsproblem
\item
  Hürde: Rotationsproblem
\item
  Hürde: Problem der Anzahl zu extrahierender Faktoren
\end{enumerate}

~

\begin{quote}
``Unfortunately, factor analysis is frequently misunderstood and often
misused. Some researchers appear to use factor analysis as a kind of
divining rod, hoping to find gold hidden underneath tons of dirt. But
there is nothing magical about the technique. {[}\(\dots\){]} Factor
analysis will yield meaningful results only when the research was
meaningful to begin with.''
\href{https://www.pearson.com/us/higher-education/program/Gregory-Psychological-Testing-History-Principles-and-Applications-7th-Edition/PGM332874.html}{Gregory
(2014, S. 165)}
\end{quote}

Konklusion: Versuchen Sie ihr Modell zu verstehen! (siehe: Selbststudium
1-3)
\end{frame}

\begin{frame}{Extraktionsproblem}
\protect\hypertarget{extraktionsproblem}{}
\begin{alertblock}{Extraktionsproblem}
  Wie extrahieren wir die Faktoren/Komponenten 
\end{alertblock}

\begin{enumerate}
\tightlist
\item
  Lösung: Bestimmung der ``Principal Components''

  \begin{itemize}
  \tightlist
  \item
    Verfahren: PCA (Principal Component Analysis/Method)
  \item
    Modellgleichung: \(R \leftarrow P = CC^{t}\)
  \item
    Note: Eigenwert-, Singulärwertzerlegung (closed form solution)
  \end{itemize}
\item
  Lösung: Iterative Bestimmung der ``Principal Components''

  \begin{itemize}
  \tightlist
  \item
    Verfahren: PAFA (Principal Axis Factor Analysis)
  \item
    Modellgleichung: \(R^* \leftarrow P = FF^{t}\)
  \item
    Note(s): Reduzierte Matrix, iterativer Prozess (convergence issues)
  \end{itemize}
\item
  Lösung: Finde die plausibelsten (``most likely'') Werte zur Repro

  \begin{itemize}
  \tightlist
  \item
    Verfahren: MLFA (Maximum Likelihood Factor Analysis)
  \item
    Modellgleichung:
    \(R \leftarrow P = \Lambda \Phi \Lambda^{t} + \Psi\)
  \item
    Note(s): Reduzierte Matrix, itterativer Prozess (convergence issues)
  \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Hauptkomponentenanalyse}
\protect\hypertarget{hauptkomponentenanalyse}{}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Old School!}
\NormalTok{(dino\_pca }\OtherTok{\textless{}{-}} \FunctionTok{princomp}\NormalTok{(X, }\AttributeTok{cor=}\ConstantTok{TRUE}\NormalTok{))}
\CommentTok{\# New School}
\NormalTok{pca\_fit }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{principal}\NormalTok{(R, }\AttributeTok{nfactors =} \DecValTok{2}\NormalTok{, }
                            \AttributeTok{rotate =} \StringTok{"none"}\NormalTok{)}
\DocumentationTok{\#\# Komponentenladungen}
\NormalTok{pca\_fit}\SpecialCharTok{$}\NormalTok{loadings}
\DocumentationTok{\#\# Kommunalitäten }
\NormalTok{pca\_fit}\SpecialCharTok{$}\NormalTok{communality}
\DocumentationTok{\#\# Uniqueness }
\NormalTok{pca\_fit}\SpecialCharTok{$}\NormalTok{uniquenesses}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Übungsaufgabe 3: Selbstexperiment}
\protect\hypertarget{uxfcbungsaufgabe-3-selbstexperiment}{}
\begin{example}
Versuchen Sie es nun selbst! Fitten sie ein PC model. Interpretieren Sie die
enstprechenden Kennwerte für ihr Model und präsentieren Sie diese mir oder ihrem
Nachbarn. Verändern Sie auch einmal die Anzahl der zu extrahierenden Faktoren
($\texttt{nfactors}$). Wie verändert sich ihre Lösung wenn sie die Zahl
vergößern, bzw. verkleinern? Wie wirken sich diese Veränderungen auf die
Interpretation Ihrer Ergebnisse aus? 
\end{example}

Anmerkung: Denken Sie daran, normalerweise kennen Sie die Anzahl der zu
extrahierenden Komponenten/Faktoren nicht. Wie man dieses Problem
angeht, dazu gleich mehr!
\end{frame}

\begin{frame}[fragile]{Principal Axis Factor Analysis}
\protect\hypertarget{principal-axis-factor-analysis}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_paf }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{fa}\NormalTok{(R, }\AttributeTok{nfactors=}\DecValTok{2}\NormalTok{, }\AttributeTok{rotate=}\StringTok{"none"}\NormalTok{, }\AttributeTok{fm=}\StringTok{"pa"}\NormalTok{)}
\CommentTok{\# Kommunalitäten}
\NormalTok{fit\_paf}\SpecialCharTok{$}\NormalTok{communality}
\CommentTok{\# Eigenwerte}
\NormalTok{fit\_paf}\SpecialCharTok{$}\NormalTok{e.values}
\CommentTok{\# Einzigartigkeit}
\NormalTok{fit\_paf}\SpecialCharTok{$}\NormalTok{uniquenesses}
\CommentTok{\# Quadrierte multiple Korrelation}
\NormalTok{fit\_paf}\SpecialCharTok{$}\NormalTok{R2}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Übungsaufgabe 4: Selbstexperiment}
\protect\hypertarget{uxfcbungsaufgabe-4-selbstexperiment}{}
\begin{example}
Versuchen Sie es nun selbst! Führen Sie eine Hauptachsenanalyse (PAF) durch.
Interpretieren Sie die enstprechenden Kennwerte für ihr Model und präsentieren
Sie diese mir oder ihrem Nachbarn. Verändern Sie auch einmal die Anzahl der zu
extrahierenden Faktoren ($\texttt{nfactors}$). Wie verändert sich ihre Lösung
wenn sie die Zahl vergößern, bzw. verkleinern? Wie wirken sich diese
Veränderungen auf die Interpretation Ihrer Ergebnisse aus?
\end{example}

Zusatz: Vergleichen Sie die Ergebnisse der PAF mit denen der PCA.
Bestehen Unterschiede zwischen den Ergebnissen? Haben Sie eine Vermutung
wie diese zustande kommen?
\end{frame}

\begin{frame}{Übungsaufgabe 5: Kritische Reflexion}
\protect\hypertarget{uxfcbungsaufgabe-5-kritische-reflexion}{}
\begin{example}
Eine Folge der Extraktion mittels mit der Hauptkomponentenmethode ist, dass die
extrahierten Faktoren unabhängig voneinander sind. Glauben Sie dem Modell
uneingeschränkt, nähmen sie damit implizit an, dass auch die zugrundeliegende
Konstrukte unabhängig voneinander sein müssten. Denken Sie an ihr Beispiel. Für
wie plausibel halten Sie diese Annahme? Diskutieren Sie (heftig)! 
\end{example}

Warnhinweis: Sollte ein Inferno entfachen, halten Sie bitte Fluchtwege
sowie Zugänge zu den Feuerlöschern frei!
\end{frame}

\begin{frame}{Maximum Likelihood Faktorenanalyse}
\protect\hypertarget{maximum-likelihood-faktorenanalyse}{}
\begin{alertblock}{Kommunalitätenproblem}
Das CFM ($\Lambda \Phi \Lambda' + \Psi$) ist unbestimmt. D.h. es hat (deutlich)
mehr unbekannte als bekannte Bestanndteile. Die Folge: Das Modell kann deshalb
nicht einfach gelöst werden, sondern muss geschätzt werden.
\end{alertblock}

\begin{itemize}
\tightlist
\item
  MLFA bietet nun als Lösung die plausibelsten (eng. ``most likely'')
  Werte zur Reproduktion der Informationen in der Korrelationsmatrix an.
\end{itemize}

\begin{quote}
``Assuming that the residual variance reflects normally distributed
random error, the most elegant statistical solution is that of maximum
likelihood'' (Revelle, in prep. S. 156)
\end{quote}
\end{frame}

\begin{frame}[fragile]{Maximum Likelihood Factor Analysis}
\protect\hypertarget{maximum-likelihood-factor-analysis}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_mlf }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{fa}\NormalTok{(R, }\AttributeTok{nfactors=}\DecValTok{2}\NormalTok{, }\AttributeTok{rotate=}\StringTok{"none"}\NormalTok{, }\AttributeTok{fm=}\StringTok{"ml"}\NormalTok{)}
\CommentTok{\# Kommunalitäten}
\NormalTok{fit\_mlf}\SpecialCharTok{$}\NormalTok{communality}
\CommentTok{\# Eigenwerte}
\NormalTok{fit\_mlf}\SpecialCharTok{$}\NormalTok{e.values}
\CommentTok{\# Einzigartigkeit}
\NormalTok{fit\_mlf}\SpecialCharTok{$}\NormalTok{uniquenesses}
\CommentTok{\# Quadrierte multiple Korrelation}
\NormalTok{fit\_mlf}\SpecialCharTok{$}\NormalTok{R2}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Übungsaufgabe 6: Selbstexperiment}
\protect\hypertarget{uxfcbungsaufgabe-6-selbstexperiment}{}
\begin{example}
Versuchen Sie es nun selbst! Führen Sie eine Maximum Likelihood Faktorenanalyse
(MLF) durch. Interpretieren Sie die enstprechenden Kennwerte für ihr Model und
präsentieren Sie diese mir oder ihrem Nachbarn. Verändern Sie erneut die Anzahl
der zu extrahierenden Faktoren ($\texttt{nfactors}$). Wie verändert sich ihre
Lösung wenn sie die Zahl vergößern, bzw. verkleinern? Wie wirken sich diese
Veränderungen auf die Interpretation Ihrer Ergebnisse aus?
\end{example}

Zusatz: Vergleichen Sie die Ergebnisse der MLF mit denen der PAF.
Bestehen Unterschiede zwischen den Ergebnissen? Haben Sie eine Vermutung
warum diese zustande kommen?
\end{frame}

\begin{frame}{Rotationsproblem}
\protect\hypertarget{rotationsproblem}{}
\begin{alertblock}{Rotationsproblem}
  Wie rotiert die erhaltene Ladungsmatrix ($\Lambda$) derart, dass eine
  möglich einfach interpretierbare Lösung daraus hervorgeht?
  \begin{equation}
    \Lambda_r = \Lamdda T 
  \end{equation}
\end{alertblock}

\begin{enumerate}
\tightlist
\item
  Lösung: Orthogonale Rotation
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Ziel: Orthogonalität aufrechterhalten
\item
  d.h. Faktoren dürfen nicht korrelieren
\item
  Restriktion: \(TT' = I\), sodass \(\Phi=I\)
\item
  z.B.: Varimax, Promax..
\end{itemize}

\begin{enumerate}
\setcounter{enumi}{1}
\tightlist
\item
  Lösung: Oblique Rotation
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Ziel: mögliche Orthogonalität auflösen
\item
  d.h. Faktoren dürfen korrelieren
\item
  Restriktion: \(TT' \neq I\), sodass \(\Phi\neq I\)
\item
  z.B.: Oblimin, Simplimax..
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Orthogonale Rotation: Varimax}
\protect\hypertarget{orthogonale-rotation-varimax}{}
\ldots maximiere die Varianz der quadrierten Ladungen

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_mlf\_vmax }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{fa}\NormalTok{(R, }\AttributeTok{nfactors=}\DecValTok{2}\NormalTok{, }\AttributeTok{rotate=}\StringTok{"varimax"}\NormalTok{, }\AttributeTok{fm=}\StringTok{"ml"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(fit\_mlf}\SpecialCharTok{$}\NormalTok{loadings, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
    \AttributeTok{xlab =} \StringTok{"Ladungen: Faktor 1"}\NormalTok{ , }\AttributeTok{ylab =} \StringTok{"Ladungen: Faktor 2"}\NormalTok{)}
\FunctionTok{points}\NormalTok{(fit\_mlf\_vmax}\SpecialCharTok{$}\NormalTok{loadings, }\AttributeTok{pch=}\DecValTok{20}\NormalTok{)}
\NormalTok{x1 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{1}\NormalTok{] ; y1 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{2}\NormalTok{]}
\NormalTok{x2 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf\_vmax}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{1}\NormalTok{] ; y2 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf\_vmax}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{2}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \FunctionTok{seq}\NormalTok{(}\DecValTok{8}\NormalTok{)) }\FunctionTok{lines}\NormalTok{(}\FunctionTok{c}\NormalTok{(x1[i], x2[i]), }\FunctionTok{c}\NormalTok{(y1[i], y2[i]))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty=}\DecValTok{2}\NormalTok{) ; }\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty=}\DecValTok{2}\NormalTok{)}
\FunctionTok{mtext}\NormalTok{(}\StringTok{"Faktorkoordinaten vor und nach Varimax Rotation"}\NormalTok{)}
\NormalTok{i }\OtherTok{\textless{}{-}} \DecValTok{8}\NormalTok{ ; s }\OtherTok{\textless{}{-}} \FloatTok{0.04}
\FunctionTok{text}\NormalTok{(}\FunctionTok{c}\NormalTok{(x1[i]}\SpecialCharTok{+}\NormalTok{s, x2[i]}\SpecialCharTok{+}\NormalTok{s), }\FunctionTok{c}\NormalTok{(y1[i]}\SpecialCharTok{+}\NormalTok{s, y2[i]}\SpecialCharTok{+}\NormalTok{s), }\FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"i\textquotesingle{}"}\NormalTok{))}
\FunctionTok{legend}\NormalTok{(}\AttributeTok{x =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"unrotated"}\NormalTok{, }\StringTok{"rotated"}\NormalTok{), }\AttributeTok{pch =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{20}\NormalTok{), }\AttributeTok{cex=}\FloatTok{0.8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{06-EFA_files/figure-beamer/unnamed-chunk-7-1} \end{center}
\end{frame}

\begin{frame}[fragile]{Let's do it (..in R)}
\protect\hypertarget{lets-do-it-..in-r}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(fit\_vmax }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{fa}\NormalTok{(R, }\AttributeTok{nfactors=}\DecValTok{2}\NormalTok{, }\AttributeTok{rotate=}\StringTok{"varimax"}\NormalTok{, }\AttributeTok{fm=}\StringTok{"ml"}\NormalTok{))}
\CommentTok{\# Kommunalitäten}
\NormalTok{fit\_vmax}\SpecialCharTok{$}\NormalTok{communality}
\CommentTok{\# Eigenwerte}
\NormalTok{fit\_vmax}\SpecialCharTok{$}\NormalTok{e.values}
\CommentTok{\# Einzigartigkeit}
\NormalTok{fit\_vmax}\SpecialCharTok{$}\NormalTok{uniquenesses}
\CommentTok{\# Quadrierte multiple Korrelation}
\NormalTok{fit\_vmax}\SpecialCharTok{$}\NormalTok{R2}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Übungsaufgabe 7: Selbstexperiment}
\protect\hypertarget{uxfcbungsaufgabe-7-selbstexperiment}{}
\begin{example}
Versuchen Sie es nun selbst! Führen Sie eine Maximum Likelihood Faktorenanalyse
(MLF) durch. Rotieren Sie anschließend die Ergebnisse mit der Varimax
rotationen. Interpretieren Sie die enstprechenden Kennwerte für ihr Model und
präsentieren Sie diese mir oder ihrem Nachbarn. Wie verändert die Rotation
ihre Interpretation Ihrer Ergebnisse aus? Vergleichen Sie die Lösung dazu mit
der unrotierten Lösung ($\texttt{mlf_fit}$).
\end{example}

Zusatz: Sie kennen das ``richtige'' Ergebnis -- Sie haben die Antworten
immerhin simuliert! Entspricht das soeben erhaltene Ergebnis dem
``richtigen'' Ergebnis? Wenn ja, warum? Falls nein, warum nicht?
\end{frame}

\begin{frame}[fragile]{Oblique Rotation: Oblimin}
\protect\hypertarget{oblique-rotation-oblimin}{}
\ldots{}``oblique'' Alternative zu Varimax das erlaubt die
Zwischenfaktorkorrelationen zu modellieren. Ist die
Zwischenfaktorkorrelation 0 entsprechen sich beide Verfahren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_mlf\_obl }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{fa}\NormalTok{(R, }\AttributeTok{nfactors=}\DecValTok{2}\NormalTok{, }\AttributeTok{rotate=}\StringTok{"oblimin"}\NormalTok{, }\AttributeTok{fm=}\StringTok{"ml"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required namespace: GPArotation
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(fit\_mlf}\SpecialCharTok{$}\NormalTok{loadings, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
    \AttributeTok{xlab =} \StringTok{"Ladungen: Faktor 1"}\NormalTok{ , }\AttributeTok{ylab =} \StringTok{"Ladungen: Faktor 2"}\NormalTok{)}
\FunctionTok{points}\NormalTok{(fit\_mlf\_obl}\SpecialCharTok{$}\NormalTok{loadings, }\AttributeTok{pch=}\DecValTok{20}\NormalTok{)}
\NormalTok{x1 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{1}\NormalTok{] ; y1 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{2}\NormalTok{]}
\NormalTok{x2 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf\_obl}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{1}\NormalTok{] ; y2 }\OtherTok{\textless{}{-}}\NormalTok{ fit\_mlf\_obl}\SpecialCharTok{$}\NormalTok{loadings[,}\DecValTok{2}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \FunctionTok{seq}\NormalTok{(}\DecValTok{8}\NormalTok{)) }\FunctionTok{lines}\NormalTok{(}\FunctionTok{c}\NormalTok{(x1[i], x2[i]), }\FunctionTok{c}\NormalTok{(y1[i], y2[i]))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty=}\DecValTok{2}\NormalTok{) ; }\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{0}\NormalTok{, }\AttributeTok{lty=}\DecValTok{2}\NormalTok{)}
\FunctionTok{mtext}\NormalTok{(}\StringTok{"Faktorkoordinaten vor und nach Oblimin Rotation"}\NormalTok{)}
\NormalTok{i }\OtherTok{\textless{}{-}} \DecValTok{8}\NormalTok{ ; s }\OtherTok{\textless{}{-}} \FloatTok{0.04}
\FunctionTok{text}\NormalTok{(}\FunctionTok{c}\NormalTok{(x1[i]}\SpecialCharTok{+}\NormalTok{s, x2[i]}\SpecialCharTok{+}\NormalTok{s), }\FunctionTok{c}\NormalTok{(y1[i]}\SpecialCharTok{+}\NormalTok{s, y2[i]}\SpecialCharTok{+}\NormalTok{s), }\FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"i\textquotesingle{}"}\NormalTok{))}
\FunctionTok{legend}\NormalTok{(}\AttributeTok{x =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"unrotated"}\NormalTok{, }\StringTok{"rotated"}\NormalTok{), }\AttributeTok{pch =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{20}\NormalTok{), }\AttributeTok{cex=}\FloatTok{0.8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{06-EFA_files/figure-beamer/unnamed-chunk-9-1} \end{center}
\end{frame}

\begin{frame}[fragile]{Let's do it (..in R)}
\protect\hypertarget{lets-do-it-..in-r-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(fit\_obl }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{fa}\NormalTok{(R, }\AttributeTok{nfactors=}\DecValTok{2}\NormalTok{, }\AttributeTok{rotate=}\StringTok{"oblimin"}\NormalTok{, }\AttributeTok{fm=}\StringTok{"ml"}\NormalTok{))}
\CommentTok{\# Kommunalitäten}
\NormalTok{fit\_obl}\SpecialCharTok{$}\NormalTok{communality}
\CommentTok{\# Eigenwerte}
\NormalTok{fit\_obl}\SpecialCharTok{$}\NormalTok{e.values}
\CommentTok{\# Einzigartigkeit}
\NormalTok{fit\_obl}\SpecialCharTok{$}\NormalTok{uniquenesses}
\CommentTok{\# Quadrierte multiple Korrelation}
\NormalTok{fit\_obl}\SpecialCharTok{$}\NormalTok{R2}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Übungsaufgabe 8: Selbstexperiment}
\protect\hypertarget{uxfcbungsaufgabe-8-selbstexperiment}{}
\begin{example}
Versuchen Sie es nun selbst! Führen Sie eine Maximum Likelihood Faktorenanalyse
(MLF) durch. Rotieren Sie anschließend die Ergebnisse mit der Oblimin-Rotation.
Interpretieren Sie erneut die enstprechenden Kennwerte für ihr Model und
präsentieren Sie diese mir oder ihrem Nachbarn. Wie verändert die Rotation ihre
Interpretation Ihrer Ergebnisse aus? Vergleichen Sie die Lösung dazu mit der
Varimax ($\texttt{mlf_vmax}$) und der unrotierten Lösung ($\texttt{mlf_fit}$).
\end{example}

Zusatz: Sie kennen das ``richtige'' Ergebnis -- Sie haben die Antworten
immerhin simuliert! Entspricht das soeben erhaltene Ergebnis dem
``richtigen'' Ergebnis? Wenn ja, warum? Falls nein, warum nicht?
\end{frame}

\begin{frame}{Problem der Anzahl zu extrahierender Faktoren}
\protect\hypertarget{problem-der-anzahl-zu-extrahierender-faktoren}{}
\begin{alertblock}{Rotationsproblem}
  Wie ermittle ich die Anazhl der zu extrahierenden Faktoren ohne sie zu kennen?
\end{alertblock}

\begin{enumerate}
\tightlist
\item
  Lösung: Kaiser Kriterium
\item
  Lösung: Scree-Test
\item
  Lösung. Horns Parllel Analyse
\end{enumerate}

Anmerkung: Es gibt mittlerweile zahlreiche Weiterentwicklungen.
Interessieren Sie sich dafür? (siehe:
\href{https://sci-hub.se/10.1080/00273171.2011.564527}{Lorenzo-Seva et
al., 2011} \&
\href{https://doi.org/10.1002/9781118489772.ch11}{Timmerman et al.,
2018})
\end{frame}

\begin{frame}{Kaiser Kriterium}
\protect\hypertarget{kaiser-kriterium}{}
\ldots Extrahiere so lange Hauptkomponenten bis diese weniger Varianz
aufklären als eine einzelne Variable aus dem Datensatz.

\includegraphics{06-EFA_files/figure-beamer/unnamed-chunk-11-1.pdf}
\end{frame}

\begin{frame}[fragile]{(Reduzierte) Korrelationsmatrix}
\protect\hypertarget{reduzierte-korrelationsmatrix}{}
\begin{verbatim}
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
\end{verbatim}

\begin{verbatim}
## $`iteration 1`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.27 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.07 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.52 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.39 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.24 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.74
## 
## $`iteration 2`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.29 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.07 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.33  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.55 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.41 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.42 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.78
## 
## $`iteration 3`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.07 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.57 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.42 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.81
## 
## $`iteration 4`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.06 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.57 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.82
\end{verbatim}
\end{frame}

\begin{frame}{PCA}
\protect\hypertarget{pca}{}
\end{frame}

\begin{frame}{PAFA}
\protect\hypertarget{pafa}{}
\end{frame}

\begin{frame}{Exkurs}
\protect\hypertarget{exkurs}{}
\end{frame}

\begin{frame}{MLFA}
\protect\hypertarget{mlfa}{}
\begin{alertblock}{Kommunalitätenproblem}
  "The problem is that in order to estimate the communalities, we need the
  loadings. Conversely, in order to estimate the loadings, we need the
  communalities." (Mair 2018, S. 24)
\end{alertblock}

Für wir die Faktoren in Anbetracht eines unterbestimmten Modells (2
Unbekannte)

It is a useful exercise to run fa using the principal axis factor method
(fm= ``pa'') and specifying the number of iterations (e.g., max.iter=2).
Then examine the size of the residuals as the number of iterations
increases. When this is done, the solution gets progressively better, in
that the size of the residuals in the off diagonal matrix become
progressively smaller.
\end{frame}

\begin{frame}{Maximum Likelihood}
\protect\hypertarget{maximum-likelihood}{}
With the data at hand, the robot tries to estimate the most plausible
(i. e., the most likely) values that are capable to optimally reproduce
the common information in the (reduced) correlation matrix.
\end{frame}

\begin{frame}{Später}
\protect\hypertarget{spuxe4ter}{}
Findet die Faktorenanalyse ihre Struktur?

Vanishing effekt -- Simulation? Korrelationsmatrix (grafisch: Vanishing
effect) (1) Faktorenanalyse mit zunehmender Zwischenfaktorkorrelation
(2) Faktorenanalyse mit abnehmenden Ladungen
\end{frame}

\begin{frame}{Fakotrscores}
\protect\hypertarget{fakotrscores}{}
Man könnte versuchen mit den Faktorscores die True Scores der Probanden
vorherzusagen
\end{frame}

\begin{frame}{Zusatzmaterial: PCA versus EFA}
\protect\hypertarget{zusatzmaterial-pca-versus-efa}{}
\textbackslash begin\{block\}\{EFA = PCA\} EFA und PCA entsprechen sich,
genau dann wenn man beim berechnen der Kennwerte die Korrelationsmatrix,
nicht die reduzierte Korrelationsmatrix verwendet wird und man als
Extraktionsmethode eine Eigenwertzerlegung der Korrelationsmatrix bzw.
eine Singulärwertzerlegung der Datenmatrix durchführt.
\textbackslash end\{alertblock\}
\end{frame}

\begin{frame}[fragile]{Zusatzmaterial: die Relevanz von Iterationen}
\protect\hypertarget{zusatzmaterial-die-relevanz-von-iterationen}{}
\ldots bei der Anpassungsgüte des Modells in der PAFA

\begin{verbatim}
##  [1] 2.508165e-02 3.040011e-03 3.681981e-04 5.153387e-05 9.036700e-06
##  [6] 1.994291e-06 5.300246e-07 1.605099e-07 1.605099e-07 1.605099e-07
\end{verbatim}

\includegraphics{06-EFA_files/figure-beamer/unnamed-chunk-13-1.pdf}
\end{frame}

\begin{frame}{Selbststudium 1: händische PCA -- Eigenwertzerlegung}
\protect\hypertarget{selbststudium-1-huxe4ndische-pca-eigenwertzerlegung}{}
\end{frame}

\begin{frame}{Selbststudium 2: händische EFA -- Singulärwertzerlegung}
\protect\hypertarget{selbststudium-2-huxe4ndische-efa-singuluxe4rwertzerlegung}{}
\end{frame}

\begin{frame}[fragile]{Selbststudium 3: reduzierte Korrelationsmatrix}
\protect\hypertarget{selbststudium-3-reduzierte-korrelationsmatrix}{}
\ldots Der Output zeigt die erst 8 Iterationen einer PAFA. Vergleichen
Sie diese mit ihre am Anfang konstruierte Korrelationsmatrix
(\(\texttt{R}\)). Achten Sie auf die Hauptdiagonalen!

\begin{verbatim}
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
## maximum iteration exceeded
\end{verbatim}

\begin{verbatim}
## $`iteration 1`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.27 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.07 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.52 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.39 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.24 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.74
## 
## $`iteration 2`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.29 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.07 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.33  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.55 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.41 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.42 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.78
## 
## $`iteration 3`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.07 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.57 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.42 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.81
## 
## $`iteration 4`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.06 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.57 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.82
## 
## $`iteration 5`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.06 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.58 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.82
## 
## $`iteration 6`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.06 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.58 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.83
## 
## $`iteration 7`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.06 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.58 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.83
## 
## $`iteration 8`
##       V1    V2    V3    V4    V5    V6    V7    V8
## V1  0.30 -0.14  0.30  0.40 -0.13  0.24 -0.05  0.34
## V2 -0.14  0.06 -0.13 -0.18  0.03 -0.09  0.00 -0.13
## V3  0.30 -0.13  0.32  0.43 -0.22  0.31 -0.13  0.45
## V4  0.40 -0.18  0.43  0.58 -0.29  0.41 -0.16  0.59
## V5 -0.13  0.03 -0.22 -0.29  0.42 -0.38  0.32 -0.54
## V6  0.24 -0.09  0.31  0.41 -0.38  0.41 -0.27  0.58
## V7 -0.05  0.00 -0.13 -0.16  0.32 -0.27  0.26 -0.38
## V8  0.34 -0.13  0.45  0.59 -0.54  0.58 -0.38  0.83
\end{verbatim}
\end{frame}

\begin{frame}{Selbststudium 3: Hintergrundwissen}
\protect\hypertarget{selbststudium-3-hintergrundwissen}{}
\begin{quote}
\ldots{[}P{]}rincipal axes factor analysis. This is similar to principal
components, except that it is done with a reduced matrix where the
diagonals are the communalities. The communalities can either be (1)
specified a priori, (2) estimated by such procedures as multiple linear
regression, or (3) found by iteratively doing an eigenvalue
decomposition and repeatedly replacing the original 1s on the diagonal
with the the value of \(1 - u^2\) where \(U^2 = diag(R−FF')\).
\end{quote}
\end{frame}

\end{document}
